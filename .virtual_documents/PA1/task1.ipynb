


import pandas as pd
from sklearn.model_selection import train_test_split
  

file = "CTG.csv"
# Read the CSV file.
data = pd.read_csv(file, skiprows=1)


# Select the relevant numerical columns.
selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',
                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',
                 'Median', 'Variance', 'Tendency', 'NSP']
data = data[selected_cols].dropna()

# Shuffle the dataset.
data_shuffled = data.sample(frac=1.0, random_state=0)

# Split into input part X and output part Y.
X = data_shuffled.drop('NSP', axis=1)

# Map the diagnosis code to a human-readable label.
def to_label(y):
    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]

Y = data_shuffled['NSP'].apply(to_label)

# Partition the data into training and test sets.
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)


X.head()


from sklearn.dummy import DummyClassifier

clf = DummyClassifier(strategy='most_frequent')


from sklearn.model_selection import cross_val_score

cross_val_score(clf, Xtrain, Ytrain)


# step 3 - train different classifiers

# Decision Tree
from sklearn.tree import DecisionTreeClassifier 

clf1 = DecisionTreeClassifier(max_depth=4) # prevent overfitting

cross_val_score(clf1, Xtrain, Ytrain)


# Random Forest 
from sklearn.ensemble import RandomForestClassifier

clf2 = RandomForestClassifier()

cross_val_score(clf2, Xtrain, Ytrain)


# LinearSVC
from sklearn.svm import LinearSVC 

clf3 = LinearSVC()

cross_val_score(clf3, Xtrain, Ytrain)


# MLP Classifier
from sklearn.neural_network import MLPClassifier  

clf4 = MLPClassifier()

cross_val_score(clf4, Xtrain, Ytrain)


from sklearn.metrics import accuracy_score
clf2.fit(Xtrain, Ytrain) # using random forest
Yguess = clf2.predict(Xtest)
print(accuracy_score(Ytest, Yguess))






