


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Read the Excel file using Pandas.
alldata = pd.read_excel('Hemnet_data.xlsx')

# # Convert the timestamp string to an integer representing the year.
alldata['year'] = pd.DatetimeIndex(alldata['Sold Date']).year

# Convert 'yes' to 1 and 'no' to 0
alldata['Balcony'] = alldata['Balcony'].map({'Yes': 1, 'No': 0})
alldata['Patio'] = alldata['Patio'].map({'Yes': 1, 'No': 0})
alldata['Lift'] = alldata['Lift'].map({'Yes': 1, 'No': 0})

# Select the 12 input columns and the output column.
selected_columns = ['Final Price (kr)', 'year',  'Num of Room', 'Living Area (mÂ²)', 'Balcony', 'Patio','Current Floor', 'Total Floor', 'Lift', 'Built Year', 'Fee (kr/month)', 'Operating Fee (kr/year)']
alldata = alldata[selected_columns]
alldata = alldata.dropna()

# Shuffle.
alldata_shuffled = alldata.sample(frac=1.0, random_state=0)
# Separate the input and output columns.
X = alldata_shuffled.drop('Final Price (kr)', axis=1)
X["Fee (kr/month)"] = X["Fee (kr/month)"].astype(str).str.contains('kr')
# For the output, we'll use the log of the sales price.
Y = alldata_shuffled['Final Price (kr)'].apply(np.  log)

# Split into training and test sets.
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)


X


Y


from sklearn.linear_model import LinearRegression

from sklearn.model_selection import cross_validate
m1 = LinearRegression()
cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')


from sklearn.metrics import mean_squared_error
  
m1.fit(Xtrain, Ytrain)
mean_squared_error(Ytest, m1.predict(Xtest))



from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

# create the models
m2 = DecisionTreeRegressor()
m3 = RandomForestRegressor()

# train models
m2.fit(Xtrain, Ytrain)
m3.fit(Xtrain, Ytrain)  

# output cross validation   
print(cross_validate(m2, Xtrain, Ytrain, scoring='neg_mean_squared_error'))
print(cross_validate(m3, Xtrain, Ytrain, scoring='neg_mean_squared_error'))

# get mse
print(mean_squared_error(Ytest, m2.predict(Xtest)))
print(mean_squared_error(Ytest, m3.predict(Xtest)))



from sklearn.ensemble import GradientBoostingRegressor

m4 = GradientBoostingRegressor(random_state=0)
m4.fit(Xtrain, Ytrain)
print(cross_validate(m4, Xtrain, Ytrain, scoring='neg_mean_squared_error'))
print(mean_squared_error(Ytest, m4.predict(Xtest)))


from sklearn.neural_network import MLPRegressor
m5 = MLPRegressor(hidden_layer_sizes=(100,), random_state=1, max_iter=2000, tol=0.1)
m5.fit(Xtrain, Ytrain)
print(cross_validate(m5, Xtrain, Ytrain, scoring='neg_mean_squared_error'))
print(mean_squared_error(Ytest, m5.predict(Xtest)))



